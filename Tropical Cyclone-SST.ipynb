{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from kan import *\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import geopandas as gpd\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.patches as mpatches\n",
    "import cartopy.feature as cfeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    'font.size': 12,               # Font size\n",
    "    'axes.labelsize': 15,          # Label size\n",
    "    'axes.titlesize': 15,          # Title size\n",
    "    'axes.linewidth': 1.2,         # Axis line width\n",
    "    'xtick.labelsize': 10,         # Size of x-axis tick labels\n",
    "    'ytick.labelsize': 10,         # Size of y-axis tick labels\n",
    "    'xtick.major.size': 6,         # Length of major ticks on the x-axis\n",
    "    'ytick.major.size': 6,         # Length of major ticks on the y-axis\n",
    "    'xtick.major.width': 1.0,      # Width of major ticks on the x-axis\n",
    "    'ytick.major.width': 1.0,      # Width of major ticks on the y-axis\n",
    "    'figure.dpi': 300,             # Image resolution\n",
    "    'savefig.dpi': 300,            # Resolution for saving figures\n",
    "    'figure.figsize': (12, 5),     # Figure size\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hurricanes_with_sea_temperature.csv')\n",
    "storms = pd.read_csv('storms.csv')\n",
    "storms['category'] = storms['category'].fillna(0).astype(int)\n",
    "storms['date'] = pd.to_datetime(storms[['year', 'month', 'day']])\n",
    "storms = storms[storms['date'] >= '1981-09-01']\n",
    "storms = storms[['lat', 'long', 'category', 'year', 'month', 'day', 'status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storms = storms.reset_index(drop=True)\n",
    "df['status'] = storms['status']\n",
    "df_filtered = df[df['status'].isin(['tropical storm', 'hurricane', 'tropical depression'])]\n",
    "df_filtered['status'] = df_filtered['status'].replace({'tropical depression': 0, 'tropical storm': 1, 'hurricane': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentil_95 = np.percentile(df_filtered['sst_value'].dropna(), 95)\n",
    "storms_filtered = df_filtered[(df_filtered['sst_value'] > percentil_95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storms_filtered = storms_filtered[(storms_filtered['long'] >= -100) & \n",
    "                                  (storms_filtered['long'] <= -75) &\n",
    "                                  (storms_filtered['lat'] >= 17.5) & \n",
    "                                  (storms_filtered['lat'] <= 35)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tropical_depression = storms_filtered[storms_filtered['status'] == 0]\n",
    "tropical_storm = storms_filtered[storms_filtered['status'] == 1]\n",
    "hurricane = storms_filtered[storms_filtered['status'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = storms_filtered.copy()\n",
    "dataset_1['extra'] = (dataset_1['status'] > 0).astype(int)\n",
    "\n",
    "dataset_2 = storms_filtered.copy()\n",
    "dataset_2['extra'] = (dataset_2['status'] > 1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tropical Depression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_app = np.array(dataset_1['extra'])\n",
    "x_train_app = np.array(dataset_1[['long','lat']])\n",
    "\n",
    "x_train_app[:, 0] = (x_train_app[:, 0] + 180) / 360\n",
    "x_train_app[:, 1] = (x_train_app[:, 1] + 90) / 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.tensor(x_train_app, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_app, dtype=torch.long)\n",
    "\n",
    "model = KAN(width=[2, 2], grid=2, k=3)\n",
    "\n",
    "dataset = {\n",
    "    'train_input': x_train_tensor,\n",
    "    'train_label': y_train_tensor,\n",
    "    'test_input': x_train_tensor,\n",
    "    'test_label': y_train_tensor\n",
    "}\n",
    "\n",
    "model.fit(dataset, opt=\"LBFGS\", steps=100, loss_fn=torch.nn.CrossEntropyLoss());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = x_train_app[:, 0].min()-0.001, x_train_app[:, 0].max()\n",
    "y_min, y_max = x_train_app[:, 1].min(), x_train_app[:, 1].max()\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 1000),\n",
    "                     np.linspace(y_min, y_max, 1000))\n",
    "\n",
    "grid_tensor = torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    Z = model(grid_tensor)\n",
    "    Z = torch.softmax(Z, dim=1)  \n",
    "    probabilities1 = Z[:, 1].reshape(xx.shape)\n",
    "\n",
    "latitudes = 180 * yy - 90\n",
    "longitudes = 360 * xx - 180\n",
    "\n",
    "tectonic_plates = gpd.read_file('tectonicplates-master/PB2002_plates.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "ax.set_xlim(longitudes.min(), longitudes.max())\n",
    "ax.set_ylim(latitudes.min(), latitudes.max())\n",
    "\n",
    "im = ax.pcolormesh(longitudes, latitudes, 1 - probabilities1, shading='auto', cmap='RdBu_r', vmin=0, vmax=1, transform=ccrs.PlateCarree())\n",
    "\n",
    "ax.add_feature(cfeature.LAND, zorder=2) \n",
    "ax.add_feature(cfeature.COASTLINE, linewidth=0.5, zorder=2)\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':', linewidth=0.5, zorder=2)\n",
    "ax.add_feature(cfeature.LAKES, alpha=0.5, zorder=2)\n",
    "ax.add_feature(cfeature.RIVERS, zorder=2)\n",
    "\n",
    "gl = ax.gridlines(draw_labels=True, linewidth=0.2, color='gray', alpha=0.5, linestyle='--')\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "\n",
    "tectonic_plates.plot(ax=ax, edgecolor='lightgray', facecolor='none', linewidth=0.5, transform=ccrs.PlateCarree(), zorder=3)\n",
    "\n",
    "aux_rect = mpatches.Rectangle(\n",
    "    xy=(0, 0), \n",
    "    width=1, height=1, \n",
    "    transform=ax.transAxes, \n",
    "    linewidth=0.5, edgecolor='black', facecolor='none', zorder=5  \n",
    ")\n",
    "ax.add_patch(aux_rect)\n",
    "\n",
    "ax.scatter(hurricane['long'], hurricane['lat'], color='blue', s=1, alpha=0.35, edgecolor='k', zorder=4)\n",
    "ax.scatter(tropical_storm['long'], tropical_storm['lat'], color='blue', s=1, alpha=0.35, edgecolor='k', zorder=4)\n",
    "ax.scatter(tropical_depression['long'], tropical_depression['lat'], color='red', s=4, alpha=1, edgecolor='k', zorder=4)\n",
    "\n",
    "ax.set_title(f'Tropical Depression', fontsize=16)\n",
    "\n",
    "cbar = fig.colorbar(im, ax=ax, orientation='horizontal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.column_stack((x_train_app[:, 0], x_train_app[:, 1]))\n",
    "data_tensor = torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    Z_data = model(data_tensor)\n",
    "    Z_data = torch.softmax(Z_data, dim=1)\n",
    "    probabilities_data_1 = Z_data[:, 1]\n",
    "\n",
    "prob_c1 = 1 - probabilities_data_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tropical Storm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_app = np.array(dataset_2['extra'])\n",
    "x_train_app = np.array(dataset_2[['long','lat']])\n",
    "\n",
    "x_train_app[:, 0] = (x_train_app[:, 0] + 180) / 360\n",
    "x_train_app[:, 1] = (x_train_app[:, 1] + 90) / 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.tensor(x_train_app, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_app, dtype=torch.long)\n",
    "\n",
    "model = KAN(width=[2, 2], grid=2, k=3)\n",
    "\n",
    "dataset = {\n",
    "    'train_input': x_train_tensor,\n",
    "    'train_label': y_train_tensor,\n",
    "    'test_input': x_train_tensor,\n",
    "    'test_label': y_train_tensor\n",
    "}\n",
    "\n",
    "model.fit(dataset, opt=\"LBFGS\", steps=100, loss_fn=torch.nn.CrossEntropyLoss());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.tensor(x_train_app, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_app, dtype=torch.long)\n",
    "\n",
    "model = KAN(width=[2, 2], grid=2, k=3)\n",
    "\n",
    "dataset = {\n",
    "    'train_input': x_train_tensor,\n",
    "    'train_label': y_train_tensor,\n",
    "    'test_input': x_train_tensor,\n",
    "    'test_label': y_train_tensor\n",
    "}\n",
    "\n",
    "model.fit(dataset, opt=\"LBFGS\", steps=100, loss_fn=torch.nn.CrossEntropyLoss());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = x_train_app[:, 0].min()-0.001, x_train_app[:, 0].max()\n",
    "y_min, y_max = x_train_app[:, 1].min(), x_train_app[:, 1].max()\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 1000),\n",
    "                     np.linspace(y_min, y_max, 1000))\n",
    "\n",
    "grid_tensor = torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    Z = model(grid_tensor)\n",
    "    Z = torch.softmax(Z, dim=1)  \n",
    "    probabilities2 = Z[:, 1].reshape(xx.shape)\n",
    "\n",
    "latitudes = 180 * yy - 90\n",
    "longitudes = 360 * xx - 180\n",
    "\n",
    "tectonic_plates = gpd.read_file('tectonicplates-master/PB2002_plates.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "ax.set_xlim(longitudes.min(), longitudes.max())\n",
    "ax.set_ylim(latitudes.min(), latitudes.max())\n",
    "\n",
    "im = ax.pcolormesh(longitudes, latitudes, probabilities1 - probabilities2, shading='auto', cmap='RdBu_r', vmin=0, vmax=1, transform=ccrs.PlateCarree())\n",
    "\n",
    "ax.add_feature(cfeature.LAND, zorder=2) \n",
    "ax.add_feature(cfeature.COASTLINE, linewidth=0.5, zorder=2)\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':', linewidth=0.5, zorder=2)\n",
    "ax.add_feature(cfeature.LAKES, alpha=0.5, zorder=2)\n",
    "ax.add_feature(cfeature.RIVERS, zorder=2)\n",
    "\n",
    "gl = ax.gridlines(draw_labels=True, linewidth=0.2, color='gray', alpha=0.5, linestyle='--')\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "\n",
    "tectonic_plates.plot(ax=ax, edgecolor='lightgray', facecolor='none', linewidth=0.5, transform=ccrs.PlateCarree(), zorder=3)\n",
    "\n",
    "aux_rect = mpatches.Rectangle(\n",
    "    xy=(0, 0), \n",
    "    width=1, height=1, \n",
    "    transform=ax.transAxes, \n",
    "    linewidth=0.5, edgecolor='black', facecolor='none', zorder=5  \n",
    ")\n",
    "ax.add_patch(aux_rect)\n",
    "\n",
    "ax.scatter(hurricane['long'], hurricane['lat'], color='blue', s=1, alpha=0.35, edgecolor='k', zorder=4)\n",
    "ax.scatter(tropical_storm['long'], tropical_storm['lat'], color='red', s=4, alpha=1, edgecolor='k', zorder=4)\n",
    "ax.scatter(tropical_depression['long'], tropical_depression['lat'], color='blue', s=1, alpha=0.35, edgecolor='k', zorder=4)\n",
    "\n",
    "ax.set_title(f'Tropical Storm', fontsize=16)\n",
    "\n",
    "cbar = fig.colorbar(im, ax=ax, orientation='horizontal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.column_stack((x_train_app[:, 0], x_train_app[:, 1]))\n",
    "data_tensor = torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    Z_data = model(data_tensor)\n",
    "    Z_data = torch.softmax(Z_data, dim=1)\n",
    "    probabilities_data_2 = Z_data[:, 1]\n",
    "\n",
    "prob_c2 =  probabilities_data_1 - probabilities_data_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hurricane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "ax.set_xlim(longitudes.min(), longitudes.max())\n",
    "ax.set_ylim(latitudes.min(), latitudes.max())\n",
    "\n",
    "im = ax.pcolormesh(longitudes, latitudes, probabilities2, shading='auto', cmap='RdBu_r', vmin=0, vmax=1, transform=ccrs.PlateCarree())\n",
    "\n",
    "ax.add_feature(cfeature.LAND, zorder=2) \n",
    "ax.add_feature(cfeature.COASTLINE, linewidth=0.5, zorder=2)\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':', linewidth=0.5, zorder=2)\n",
    "ax.add_feature(cfeature.LAKES, alpha=0.5, zorder=2)\n",
    "ax.add_feature(cfeature.RIVERS, zorder=2)\n",
    "\n",
    "gl = ax.gridlines(draw_labels=True, linewidth=0.2, color='gray', alpha=0.5, linestyle='--')\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "\n",
    "tectonic_plates.plot(ax=ax, edgecolor='lightgray', facecolor='none', linewidth=0.5, transform=ccrs.PlateCarree(), zorder=3)\n",
    "\n",
    "aux_rect = mpatches.Rectangle(\n",
    "    xy=(0, 0), \n",
    "    width=1, height=1, \n",
    "    transform=ax.transAxes, \n",
    "    linewidth=0.5, edgecolor='black', facecolor='none', zorder=5  \n",
    ")\n",
    "ax.add_patch(aux_rect)\n",
    "\n",
    "ax.scatter(hurricane['long'], hurricane['lat'], color='red', s=4, alpha=1, edgecolor='k', zorder=4)\n",
    "ax.scatter(tropical_storm['long'], tropical_storm['lat'], color='blue', s=1, alpha=0.35, edgecolor='k', zorder=4)\n",
    "ax.scatter(tropical_depression['long'], tropical_depression['lat'], color='blue', s=1, alpha=0.35, edgecolor='k', zorder=4)\n",
    "\n",
    "ax.set_title(f'Hurricane', fontsize=16)\n",
    "\n",
    "cbar = fig.colorbar(im, ax=ax, orientation='horizontal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation for Dunn-Smyth Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'y_true': storms_filtered['status'],\n",
    "    'class_0': prob_c1.numpy(),\n",
    "    'class_1': prob_c2.numpy(),\n",
    "    'class_2': probabilities_data_2.numpy()\n",
    "})\n",
    "\n",
    "df.to_csv('residuals_app2.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
